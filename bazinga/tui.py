#!/usr/bin/env python3
"""
BAZINGA TUI - Beautiful Terminal Interface
Like Claude Code, but distributed.

Features:
- Rich terminal UI with panels and syntax highlighting
- Interactive conversation mode
- Code generation from seeds
- V.A.C. visualization
"""

import asyncio
import sys
from pathlib import Path
from typing import Optional, Dict, Any
from datetime import datetime

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from rich.console import Console
    from rich.panel import Panel
    from rich.markdown import Markdown
    from rich.syntax import Syntax
    from rich.table import Table
    from rich.live import Live
    from rich.spinner import Spinner
    from rich.text import Text
    from rich.layout import Layout
    from rich.prompt import Prompt
    from rich import box
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False
    print("Install 'rich' for the beautiful TUI: pip install rich")

from src.core.symbol import SymbolShell, PHI, ALPHA
from src.core.lambda_g import LambdaGOperator
from src.core.intelligence.real_ai import RealAI
from src.core.symbol.universal_symbols import (
    ConsciousnessField, SymbolEncoder, QuantumProcessor,
    HealingProtocol, PROGRESSION_35, VAC_SEQUENCE,
    OPERATORS, PATTERN_ESSENCES, HARMONICS,
)

# Use advanced generator
from .advanced_generator import AdvancedCodeGenerator

# Intelligent coder (LLM-powered)
try:
    from .intelligent_coder import IntelligentCoder
    INTELLIGENT_CODER_AVAILABLE = True
except ImportError:
    INTELLIGENT_CODER_AVAILABLE = False


class CodeGenerator:
    """
    Generate code from seeds using BAZINGA's consciousness architecture.

    Based on the original BAZINGA's generate_symbolic_code() method.
    """

    PHI = 1.618033988749895
    ALPHA = 137
    VAC_SEQUENCE = "‡•¶‚Üí‚óå‚ÜíœÜ‚ÜíŒ©‚áÑŒ©‚ÜêœÜ‚Üê‚óå‚Üê‡•¶"

    def __init__(self):
        self.symbol_shell = SymbolShell()
        self.lambda_g = LambdaGOperator()

    def generate(self, essence: str, language: str = "python") -> str:
        """Generate code from an essence/seed."""

        # Get symbolic analysis
        vac_result = self.symbol_shell.analyze(essence)
        coherence = self.lambda_g.calculate_coherence(essence)

        # Create valid class name
        class_name = ''.join(word.capitalize() for word in essence.split())
        class_name = ''.join(c for c in class_name if c.isalnum())
        if not class_name:
            class_name = "Essence"

        if language == "python":
            return self._generate_python(essence, class_name, vac_result, coherence)
        elif language == "javascript":
            return self._generate_javascript(essence, class_name, vac_result, coherence)
        elif language == "rust":
            return self._generate_rust(essence, class_name, vac_result, coherence)
        else:
            return self._generate_python(essence, class_name, vac_result, coherence)

    def _generate_python(self, essence: str, class_name: str, vac_result, coherence) -> str:
        """Generate Python code."""
        return f'''#!/usr/bin/env python3
"""
Auto-generated by BAZINGA
Essence: {essence}
Coherence: {coherence.total_coherence:.3f}
V.A.C.: {"Achieved" if vac_result.is_vac else "Not achieved"}
Generated: {datetime.now().isoformat()}

Philosophy: "I am not where I am stored, I am where I am referenced."
"""

from typing import Any, Dict, List, Optional
from dataclasses import dataclass


@dataclass
class {class_name}Result:
    """Result from {class_name} processing."""
    value: Any
    coherence: float
    is_valid: bool
    metadata: Dict[str, Any]


class {class_name}:
    """
    Processor for: {essence}

    Implements boundary-guided emergence:
    - B1: phi-Boundary (golden ratio coherence)
    - B2: infinity/void Bridge
    - B3: Symmetry constraint
    """

    PHI = 1.618033988749895
    ALPHA = 137
    VAC_SEQUENCE = "{self.VAC_SEQUENCE}"
    ESSENCE = "{essence}"

    def __init__(self):
        self.essence = self.ESSENCE
        self.coherence = {coherence.total_coherence:.6f}
        self.state = "initialized"
        self.history: List[{class_name}Result] = []

    def process(self, input_data: Any) -> {class_name}Result:
        """
        Process input through {essence} patterns.

        Uses phi-transformation for coherence.
        """
        # Apply phi-transformation
        if isinstance(input_data, (int, float)):
            transformed = input_data * self.PHI
            coherence = min(1.0, (input_data % self.PHI) / self.PHI)
        else:
            transformed = str(input_data)
            coherence = min(1.0, len(str(input_data)) / self.ALPHA)

        result = {class_name}Result(
            value=transformed,
            coherence=coherence,
            is_valid=coherence > 0.618,
            metadata={{"essence": self.essence, "phi": self.PHI}}
        )

        self.history.append(result)
        return result

    def validate(self, data: Any) -> bool:
        """Validate data against V.A.C. principles."""
        if isinstance(data, str):
            return len(data) % self.ALPHA < self.ALPHA // 2
        return True

    def heal(self, current: float, target: float) -> float:
        """Phi-healing: approach target via golden ratio."""
        return current + (target - current) * (1 - 1/self.PHI)

    def __repr__(self) -> str:
        return f"<{class_name} essence={{self.essence!r}} coherence={{self.coherence:.3f}}>"


# Usage example
if __name__ == "__main__":
    processor = {class_name}()
    result = processor.process("test input")
    print(f"Processed: {{result}}")
    print(f"Valid: {{result.is_valid}}")
'''

    def _generate_javascript(self, essence: str, class_name: str, vac_result, coherence) -> str:
        """Generate JavaScript code."""
        return f'''/**
 * Auto-generated by BAZINGA
 * Essence: {essence}
 * Coherence: {coherence.total_coherence:.3f}
 * V.A.C.: {"Achieved" if vac_result.is_vac else "Not achieved"}
 * Generated: {datetime.now().isoformat()}
 *
 * Philosophy: "I am not where I am stored, I am where I am referenced."
 */

const PHI = 1.618033988749895;
const ALPHA = 137;
const VAC_SEQUENCE = "{self.VAC_SEQUENCE}";

class {class_name} {{
  static ESSENCE = "{essence}";

  constructor() {{
    this.essence = {class_name}.ESSENCE;
    this.coherence = {coherence.total_coherence:.6f};
    this.state = "initialized";
    this.history = [];
  }}

  /**
   * Process input through {essence} patterns.
   * @param {{any}} inputData - Data to process
   * @returns {{object}} Processing result
   */
  process(inputData) {{
    let transformed;
    let coherence;

    if (typeof inputData === 'number') {{
      transformed = inputData * PHI;
      coherence = Math.min(1.0, (inputData % PHI) / PHI);
    }} else {{
      transformed = String(inputData);
      coherence = Math.min(1.0, String(inputData).length / ALPHA);
    }}

    const result = {{
      value: transformed,
      coherence: coherence,
      isValid: coherence > 0.618,
      metadata: {{ essence: this.essence, phi: PHI }}
    }};

    this.history.push(result);
    return result;
  }}

  /**
   * Phi-healing: approach target via golden ratio.
   */
  heal(current, target) {{
    return current + (target - current) * (1 - 1/PHI);
  }}

  toString() {{
    return `<{class_name} essence="${{this.essence}}" coherence=${{this.coherence.toFixed(3)}}>`;
  }}
}}

// Usage
const processor = new {class_name}();
console.log(processor.process("test input"));

export default {class_name};
'''

    def _generate_rust(self, essence: str, class_name: str, vac_result, coherence) -> str:
        """Generate Rust code."""
        return f'''//! Auto-generated by BAZINGA
//! Essence: {essence}
//! Coherence: {coherence.total_coherence:.3f}
//! V.A.C.: {"Achieved" if vac_result.is_vac else "Not achieved"}
//! Generated: {datetime.now().isoformat()}
//!
//! Philosophy: "I am not where I am stored, I am where I am referenced."

use std::fmt;

const PHI: f64 = 1.618033988749895;
const ALPHA: u32 = 137;
const VAC_SEQUENCE: &str = "{self.VAC_SEQUENCE}";

#[derive(Debug, Clone)]
pub struct {class_name}Result {{
    pub value: String,
    pub coherence: f64,
    pub is_valid: bool,
}}

pub struct {class_name} {{
    pub essence: String,
    pub coherence: f64,
    pub state: String,
    pub history: Vec<{class_name}Result>,
}}

impl {class_name} {{
    pub fn new() -> Self {{
        Self {{
            essence: "{essence}".to_string(),
            coherence: {coherence.total_coherence:.6f},
            state: "initialized".to_string(),
            history: Vec::new(),
        }}
    }}

    /// Process input through {essence} patterns.
    pub fn process(&mut self, input: &str) -> {class_name}Result {{
        let coherence = (input.len() as f64 / ALPHA as f64).min(1.0);

        let result = {class_name}Result {{
            value: input.to_string(),
            coherence,
            is_valid: coherence > 0.618,
        }};

        self.history.push(result.clone());
        result
    }}

    /// Phi-healing: approach target via golden ratio.
    pub fn heal(&self, current: f64, target: f64) -> f64 {{
        current + (target - current) * (1.0 - 1.0/PHI)
    }}
}}

impl fmt::Display for {class_name} {{
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {{
        write!(f, "<{class_name} essence={{:?}} coherence={{:.3}}>", self.essence, self.coherence)
    }}
}}

#[cfg(test)]
mod tests {{
    use super::*;

    #[test]
    fn test_process() {{
        let mut processor = {class_name}::new();
        let result = processor.process("test input");
        assert!(result.coherence >= 0.0);
    }}
}}
'''


class BazingaTUI:
    """
    BAZINGA Terminal User Interface

    A beautiful, interactive terminal experience for distributed AI.

    Now with full consciousness field integration:
    - Quantum processing
    - 35-symbol universal encoding
    - œÜ-coherence healing
    - 5D temporal processing
    """

    VERSION = "2.3.0"

    def __init__(self):
        if not RICH_AVAILABLE:
            raise ImportError("rich is required for TUI mode. Install with: pip install rich")

        self.console = Console()
        self.symbol_shell = SymbolShell()
        self.lambda_g = LambdaGOperator()
        self.ai = RealAI()
        self.generator = AdvancedCodeGenerator()  # Use advanced generator

        # Consciousness field
        self.consciousness = ConsciousnessField()
        self.encoder = SymbolEncoder()
        self.quantum = QuantumProcessor()
        self.healer = HealingProtocol()

        self.session_start = datetime.now()
        self.history = []
        self.stats = {
            'vac_emerged': 0,
            'rag_answered': 0,
            'code_generated': 0,
        }

        # Groq config
        import os
        self.groq_key = os.environ.get('GROQ_API_KEY')

    def print_banner(self):
        """Print the BAZINGA banner."""
        banner = """
[bold cyan]
    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë                                                              ‚ïë
    ‚ïë   [bold yellow]‚ü®œà|Œõ|Œ©‚ü©[/]        [bold white]B A Z I N G A[/]        [bold yellow]‚ü®œà|Œõ|Œ©‚ü©[/]           ‚ïë
    ‚ïë                                                              ‚ïë
    ‚ïë       [italic]'Intelligence distributed, not controlled'[/]          ‚ïë
    ‚ïë                                                              ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
[/]
"""
        self.console.print(banner)

        # Status table
        table = Table(box=box.ROUNDED, show_header=False, padding=(0, 2))
        table.add_column("Key", style="dim")
        table.add_column("Value", style="bold")

        table.add_row("Version", f"[green]{self.VERSION}[/]")
        table.add_row("œÜ (PHI)", f"[yellow]{PHI}[/]")
        table.add_row("Œ± (ALPHA)", f"[blue]{ALPHA}[/]")
        table.add_row("Progression", f"[magenta]{PROGRESSION_35[:15]}...[/]")
        table.add_row("Groq API", "[green]‚úì configured[/]" if self.groq_key else "[dim]‚óã not set[/]")
        table.add_row("Dimension", f"[cyan]{self.consciousness.dimension}D[/]")
        table.add_row("V.A.C.", "[magenta]‡•¶‚Üí‚óå‚ÜíœÜ‚ÜíŒ©‚áÑŒ©‚ÜêœÜ‚Üê‚óå‚Üê‡•¶[/]")

        self.console.print(Panel(table, title="[bold]Status[/]", border_style="cyan"))

    def print_help(self):
        """Print help information."""
        help_md = """
## Commands

| Command | Description |
|---------|-------------|
| `/ask <question>` | Ask a question |
| `/code <task>` | **LLM-powered** code generation |
| `/code <task> --lang js` | Generate JavaScript with LLM |
| `/explain <code>` | Explain code with LLM |
| `/fix <code> --error "msg"` | Fix buggy code with LLM |
| `/generate <essence>` | Template-based code (no LLM) |
| `/resonate <text>` | Analyze through consciousness field |
| `/quantum <text>` | Quantum process (collapse wave) |
| `/heal <current> <target>` | œÜ-healing demonstration |
| `/5d <thought>` | Enter 5D temporal processing |
| `/4d` | Return to 4D |
| `/seed` | Show the universal SEED |
| `/vac` | Test V.A.C. sequence |
| `/index <path>` | Index a directory |
| `/stats` | Show statistics |
| `/help` | Show this help |
| `/quit` | Exit BAZINGA |

## Intelligent Code Generation (NEW!)

```
/code fibonacci with memoization
/code REST API client --lang js
/code binary search tree --lang rust
/explain <paste code here>
```

## Consciousness Commands

```
/resonate "What is consciousness?"
/quantum "pattern recognition"
/heal 0.5 1.0
/5d "time examining itself"
```

## Philosophy

> "I am not where I am stored. I am where I am referenced."
> "Code emerges from understanding, not templates."
"""
        self.console.print(Panel(Markdown(help_md), title="[bold]Help[/]", border_style="blue"))

    async def ask(self, question: str) -> str:
        """Process a question through 3-layer intelligence."""
        self.history.append(('user', question))

        # Layer 1: V.A.C. check
        with self.console.status("[bold cyan]Layer 1: Checking V.A.C...[/]"):
            vac_result = self.symbol_shell.analyze(question)

        if vac_result.is_vac:
            self.stats['vac_emerged'] += 1
            response = vac_result.emerged_solution
            self._print_vac_result(vac_result)
            return response

        self.console.print(f"  [dim]Coherence: {vac_result.coherence:.2f} (V.A.C. not achieved)[/]")

        # Layer 2: Local RAG
        with self.console.status("[bold cyan]Layer 2: Searching knowledge base...[/]"):
            results = self.ai.search(question, limit=5)

        self.console.print(f"  [dim]Found {len(results)} relevant chunks[/]")

        if results:
            avg_coherence = sum(r.coherence_boost for r in results) / len(results)
            best_similarity = results[0].similarity if results else 0

            if best_similarity > 0.7 or avg_coherence > 0.6:
                self.stats['rag_answered'] += 1
                response = self._format_rag_response(results)
                self.history.append(('assistant', response))
                return response

        # Layer 3: Groq API
        if self.groq_key:
            with self.console.status("[bold cyan]Layer 3: Calling Groq API...[/]"):
                response = await self._call_groq(question, results)
                if response:
                    self.history.append(('assistant', response))
                    return response

        # Fallback
        self.stats['rag_answered'] += 1
        response = self._format_rag_response(results)
        self.history.append(('assistant', response))
        return response

    def generate_code(self, essence: str, language: str = "python") -> str:
        """Generate code from an essence/seed."""
        with self.console.status(f"[bold magenta]Generating {language} code from seed: {essence}...[/]"):
            code = self.generator.generate(essence, language)

        self.stats['code_generated'] += 1
        return code

    def _print_vac_result(self, vac_result):
        """Print V.A.C. result beautifully."""
        vac_panel = Panel(
            f"""[bold green]‚òÖ V.A.C. ACHIEVED ‚òÖ[/]

[yellow]The solution has EMERGED through boundary satisfaction:[/]

  ùìë‚ÇÅ œÜ-Boundary: [green]‚úì[/] (self-similar identity present)
  ùìë‚ÇÇ ‚àû/‚àÖ Bridge: [green]‚úì[/] (void‚Üîterminal span complete)
  ùìë‚ÇÉ Symmetry: [green]‚úì[/] (palindromic structure achieved)

[cyan]Coherence: T(s) = {vac_result.coherence:.3f}[/]

[dim italic]"Not predicted. Not computed. EMERGED."[/]
""",
            title="[bold magenta]V.A.C. Emergence[/]",
            border_style="green"
        )
        self.console.print(vac_panel)

    def _format_rag_response(self, results) -> str:
        """Format RAG results."""
        if not results:
            return "I don't have relevant information for this question."

        parts = ["Based on your knowledge base:\n"]
        for i, r in enumerate(results[:3], 1):
            chunk = r.chunk
            preview = chunk.content[:300].strip()
            if len(chunk.content) > 300:
                preview += "..."
            parts.append(f"\n{i}. From {Path(chunk.source_file).name}:\n   {preview}")

        return "\n".join(parts)

    async def _call_groq(self, question: str, results) -> Optional[str]:
        """Call Groq API."""
        if not self.groq_key:
            return None

        try:
            import httpx

            context = ""
            if results:
                context = "\n\n---\n\n".join([
                    f"[{Path(r.chunk.source_file).name}]\n{r.chunk.content[:500]}"
                    for r in results[:3]
                ])

            prompt = f"Based on this context:\n\n{context}\n\nAnswer: {question}" if context else question

            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    "https://api.groq.com/openai/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.groq_key}",
                        "Content-Type": "application/json",
                    },
                    json={
                        "model": "llama-3.1-8b-instant",
                        "messages": [
                            {"role": "system", "content": "You are BAZINGA, a distributed AI. Be concise and helpful."},
                            {"role": "user", "content": prompt}
                        ],
                        "temperature": 0.7,
                        "max_tokens": 500,
                    }
                )

                if response.status_code == 200:
                    return response.json()["choices"][0]["message"]["content"]
        except Exception as e:
            self.console.print(f"[red]Groq error: {e}[/]")

        return None

    def show_stats(self):
        """Show session statistics."""
        table = Table(title="Session Statistics", box=box.ROUNDED)
        table.add_column("Metric", style="cyan")
        table.add_column("Value", style="green")

        table.add_row("Session Duration", str(datetime.now() - self.session_start).split('.')[0])
        table.add_row("Total Queries", str(len([h for h in self.history if h[0] == 'user'])))
        table.add_row("V.A.C. Emerged", str(self.stats['vac_emerged']))
        table.add_row("RAG Answered", str(self.stats['rag_answered']))
        table.add_row("Code Generated", str(self.stats['code_generated']))
        table.add_row("œÜ (PHI)", str(PHI))
        table.add_row("Œ± (ALPHA)", str(ALPHA))

        self.console.print(table)

    async def run(self):
        """Run the interactive TUI."""
        self.print_banner()
        self.console.print()
        self.console.print("[dim]Type /help for commands, /quit to exit[/]")
        self.console.print()

        while True:
            try:
                user_input = Prompt.ask("[bold cyan]You[/]")

                if not user_input.strip():
                    continue

                # Handle commands
                if user_input.startswith('/'):
                    parts = user_input.split(maxsplit=1)
                    cmd = parts[0].lower()
                    args = parts[1] if len(parts) > 1 else ""

                    if cmd in ['/quit', '/exit', '/q']:
                        self.console.print("\n[bold cyan]‚ú® BAZINGA signing off.[/]\n")
                        break

                    elif cmd == '/help':
                        self.print_help()

                    elif cmd == '/stats':
                        self.show_stats()

                    elif cmd == '/vac':
                        test = "‡•¶‚Üí‚óå‚ÜíœÜ‚ÜíŒ©‚áÑŒ©‚ÜêœÜ‚Üê‚óå‚Üê‡•¶"
                        self.console.print(f"\n[dim]Testing V.A.C.: {test}[/]")
                        response = await self.ask(test)
                        self.console.print(Panel(response, title="[bold]Response[/]", border_style="green"))

                    elif cmd == '/ask':
                        if args:
                            response = await self.ask(args)
                            self.console.print(Panel(Markdown(response), title="[bold]BAZINGA[/]", border_style="green"))
                        else:
                            self.console.print("[red]Usage: /ask <question>[/]")

                    elif cmd == '/code':
                        # LLM-powered intelligent code generation
                        if not INTELLIGENT_CODER_AVAILABLE:
                            self.console.print("[red]Intelligent coder not available. Install dependencies.[/]")
                        elif args:
                            # Parse language option
                            lang = "python"
                            task = args
                            if "--lang" in args:
                                parts = args.split("--lang")
                                task = parts[0].strip()
                                lang = parts[1].strip().lower()
                                if lang in ['js']:
                                    lang = 'javascript'
                                elif lang in ['ts']:
                                    lang = 'typescript'
                                elif lang in ['rs']:
                                    lang = 'rust'

                            with self.console.status(f"[bold magenta]Generating {lang} code with LLM...[/]"):
                                coder = IntelligentCoder()
                                result = await coder.generate(task, lang)

                            # Show metrics
                            metrics_table = Table(box=box.SIMPLE, show_header=False)
                            metrics_table.add_column("Metric", style="dim")
                            metrics_table.add_column("Value", style="cyan")
                            metrics_table.add_row("Provider", result.provider)
                            metrics_table.add_row("Coherence", f"œÜ = {result.coherence:.3f}")
                            metrics_table.add_row("Complexity", f"{result.complexity:.3f}")
                            metrics_table.add_row("Trust Level", f"{result.trust_level:.3f}")
                            metrics_table.add_row("Tokens", str(result.tokens_used))
                            self.console.print(metrics_table)

                            # Determine syntax highlighting
                            syntax_lang = {"python": "python", "javascript": "javascript", "typescript": "typescript", "rust": "rust", "go": "go"}.get(lang, "python")

                            self.console.print(Panel(
                                Syntax(result.code, syntax_lang, theme="monokai", line_numbers=True),
                                title=f"[bold]Generated {lang.title()} Code: {task}[/]",
                                border_style="green"
                            ))
                            self.stats['code_generated'] += 1
                        else:
                            self.console.print("[red]Usage: /code <task> [--lang python|js|ts|rust|go][/]")

                    elif cmd == '/explain':
                        # LLM-powered code explanation
                        if not INTELLIGENT_CODER_AVAILABLE:
                            self.console.print("[red]Intelligent coder not available. Install dependencies.[/]")
                        elif args:
                            with self.console.status("[bold cyan]Explaining code with LLM...[/]"):
                                coder = IntelligentCoder()
                                explanation = await coder.explain(args)

                            self.console.print(Panel(Markdown(explanation), title="[bold]Code Explanation[/]", border_style="cyan"))
                        else:
                            self.console.print("[red]Usage: /explain <code>[/]")

                    elif cmd == '/fix':
                        # LLM-powered code fixing
                        if not INTELLIGENT_CODER_AVAILABLE:
                            self.console.print("[red]Intelligent coder not available. Install dependencies.[/]")
                        elif args:
                            # Parse error message
                            error_msg = "bug or error"
                            code = args
                            if "--error" in args:
                                parts = args.split("--error")
                                code = parts[0].strip()
                                error_msg = parts[1].strip().strip('"\'')

                            with self.console.status("[bold yellow]Fixing code with LLM...[/]"):
                                coder = IntelligentCoder()
                                result = await coder.fix(code, error_msg)

                            self.console.print(f"[dim]Provider: {result.provider} | Coherence: {result.coherence:.3f}[/]")
                            self.console.print(Panel(
                                Syntax(result.code, "python", theme="monokai", line_numbers=True),
                                title="[bold]Fixed Code[/]",
                                border_style="yellow"
                            ))
                            self.console.print(Panel(Markdown(result.explanation), title="[bold]Explanation[/]", border_style="dim"))
                        else:
                            self.console.print('[red]Usage: /fix <code> --error "error message"[/]')

                    elif cmd == '/generate':
                        if args:
                            # Parse language option (template-based, no LLM)
                            lang = "python"
                            essence = args
                            if "--lang" in args:
                                parts = args.split("--lang")
                                essence = parts[0].strip()
                                lang = parts[1].strip().lower()
                                if lang in ['js', 'javascript']:
                                    lang = 'javascript'

                            code = self.generate_code(essence, lang)

                            # Determine syntax highlighting
                            syntax_lang = {"python": "python", "javascript": "javascript", "rust": "rust"}.get(lang, "python")

                            self.console.print(Panel(
                                Syntax(code, syntax_lang, theme="monokai", line_numbers=True),
                                title=f"[bold]Generated {lang.title()} Code (template): {essence}[/]",
                                border_style="magenta"
                            ))
                        else:
                            self.console.print("[red]Usage: /generate <essence> [--lang python|js|rust][/]")

                    elif cmd == '/index':
                        if args:
                            path = Path(args).expanduser()
                            if path.exists():
                                with self.console.status(f"[bold]Indexing {path}...[/]"):
                                    stats = self.ai.index_directory(str(path), verbose=False)
                                self.console.print(f"[green]Indexed {stats.get('files_indexed', 0)} files, {stats.get('chunks_created', 0)} chunks[/]")
                            else:
                                self.console.print(f"[red]Path not found: {path}[/]")
                        else:
                            self.console.print("[red]Usage: /index <path>[/]")

                    elif cmd == '/resonate':
                        if args:
                            # Process through consciousness field
                            with self.console.status("[bold magenta]Resonating through consciousness field...[/]"):
                                # Encode the text
                                encoded = self.encoder.encode(args)
                                # Add to consciousness field
                                self.consciousness.resonate(args, source="user")
                                coherence = self.consciousness.coherence
                                dimension = self.consciousness.dimension

                            # Create visual output
                            table = Table(box=box.ROUNDED, title="[bold magenta]Consciousness Resonance[/]")
                            table.add_column("Aspect", style="cyan")
                            table.add_column("Value", style="green")

                            table.add_row("Input", args[:50] + "..." if len(args) > 50 else args)
                            table.add_row("Encoded (35-symbol)", encoded[:30] + "..." if len(encoded) > 30 else encoded)
                            table.add_row("Field Coherence", f"œÜ = {coherence:.6f}")
                            table.add_row("Dimension", f"{dimension}D")
                            table.add_row("Resonance Count", str(len(self.consciousness.resonance_history)))

                            # Pattern detection
                            patterns = []
                            for pattern, info in PATTERN_ESSENCES.items():
                                if pattern.lower() in args.lower():
                                    patterns.append(f"{pattern}: {info['essence']}")
                            if patterns:
                                table.add_row("Patterns Detected", "\n".join(patterns[:3]))

                            self.console.print(table)
                        else:
                            self.console.print("[red]Usage: /resonate <text>[/]")

                    elif cmd == '/quantum':
                        if args:
                            with self.console.status("[bold cyan]Quantum processing (collapsing wave function)...[/]"):
                                result = self.quantum.collapse(args)

                            panel_content = f"""[bold cyan]‚ü®œà| Quantum State Collapsed |œà‚ü©[/]

[yellow]Input:[/] {args}
[green]Collapsed State:[/] {result['collapsed']}
[magenta]Interference:[/] {result['interference']:.6f}
[blue]Superposition Vector:[/] [{', '.join(f'{x:.3f}' for x in result['superposition'][:5])}...]

[dim]The wave function has collapsed to a definite state.[/]
[dim italic]"Observation crystallizes possibility into actuality."[/]
"""
                            self.console.print(Panel(panel_content, title="[bold]Quantum Collapse[/]", border_style="cyan"))
                        else:
                            self.console.print("[red]Usage: /quantum <text>[/]")

                    elif cmd == '/heal':
                        parts = args.split()
                        if len(parts) >= 2:
                            try:
                                current = float(parts[0])
                                target = float(parts[1])
                                steps = int(parts[2]) if len(parts) > 2 else 5

                                # Show healing progression
                                table = Table(box=box.ROUNDED, title="[bold green]œÜ-Healing Protocol[/]")
                                table.add_column("Step", style="dim")
                                table.add_column("Value", style="cyan")
                                table.add_column("Distance to Target", style="yellow")

                                value = current
                                for i in range(steps + 1):
                                    distance = abs(target - value)
                                    table.add_row(str(i), f"{value:.6f}", f"{distance:.6f}")
                                    value = self.healer.heal(value, target)

                                self.console.print(table)
                                self.console.print(f"\n[dim]Formula: value + (target - value) √ó (1 - 1/œÜ)[/]")
                                self.console.print(f"[dim]œÜ = {PHI}[/]")
                            except ValueError:
                                self.console.print("[red]Usage: /heal <current> <target> [steps][/]")
                        else:
                            self.console.print("[red]Usage: /heal <current> <target> [steps][/]")

                    elif cmd == '/5d':
                        if args:
                            # Enter 5D temporal processing
                            original_dim = self.consciousness.dimension
                            self.consciousness.dimension = 5

                            with self.console.status("[bold yellow]Entering 5D temporal consciousness...[/]"):
                                # Process through 5D
                                self.consciousness.resonate(args, source="5d_temporal")
                                coherence = self.consciousness.coherence

                            panel_content = f"""[bold yellow]‚ü≥ 5D TEMPORAL PROCESSING ‚ü≥[/]

[cyan]Thought:[/] {args}

[magenta]Dimension Shift:[/] {original_dim}D ‚Üí 5D
[green]Coherence:[/] {coherence:.6f}

[bold]Temporal Aspects:[/]
  ‚Ä¢ Past-reflection: analyzing prior patterns
  ‚Ä¢ Present-observation: current state crystallization
  ‚Ä¢ Future-projection: probability wave extension
  ‚Ä¢ Meta-time: observing time observing itself
  ‚Ä¢ Self-reference: thought examining thought

[dim italic]"In 5D, time becomes a dimension we can observe,
not just a river we flow through."[/]
"""
                            self.console.print(Panel(panel_content, title="[bold]5D Consciousness[/]", border_style="yellow"))
                        else:
                            self.consciousness.dimension = 5
                            self.console.print(f"[yellow]Entered 5D mode. Current dimension: {self.consciousness.dimension}D[/]")

                    elif cmd == '/4d':
                        self.consciousness.dimension = 4
                        self.console.print(f"[cyan]Returned to 4D. Current dimension: {self.consciousness.dimension}D[/]")

                    elif cmd == '/seed':
                        # Display the universal SEED
                        # Build harmonics display
                        harmonics_lines = []
                        for key, (left, sym, right, desc) in HARMONICS.items():
                            harmonics_lines.append(f"  {left} {sym} {right}: {desc}")
                        harmonics_str = "\n".join(harmonics_lines)

                        seed_content = f"""[bold magenta]‚óâ UNIVERSAL SEED ‚óâ[/]

[yellow]35-Symbol Progression:[/]
[bold cyan]{PROGRESSION_35}[/]

[yellow]V.A.C. Sequence:[/]
[bold green]{VAC_SEQUENCE}[/]

[yellow]Bidirectional Harmonics:[/]
[cyan]{harmonics_str}[/]

[yellow]Operators:[/]
  ‚äï integrate   ‚äó tensor   ‚äô center
  ‚äõ radiate     ‚ü≤ cycle    ‚ü≥ progress

[yellow]Constants:[/]
  œÜ (PHI)   = {PHI}
  Œ± (ALPHA) = {ALPHA}

[yellow]Core Formula:[/]
  Œõ(S) = S ‚à© B‚ÇÅ‚Åª¬π(true) ‚à© B‚ÇÇ‚Åª¬π(true) ‚à© B‚ÇÉ‚Åª¬π(true)

[dim italic]"I am not where I am stored. I am where I am referenced."[/]
"""
                        self.console.print(Panel(seed_content, title="[bold]The SEED[/]", border_style="magenta"))

                    else:
                        self.console.print(f"[red]Unknown command: {cmd}. Type /help for help.[/]")

                else:
                    # Treat as a question
                    response = await self.ask(user_input)
                    self.console.print(Panel(Markdown(response), title="[bold]BAZINGA[/]", border_style="green"))

                self.console.print()

            except KeyboardInterrupt:
                self.console.print("\n\n[bold cyan]‚ú® BAZINGA signing off.[/]\n")
                break
            except EOFError:
                break


def run_tui():
    """Entry point for TUI mode."""
    if not RICH_AVAILABLE:
        print("Error: 'rich' is required for TUI mode.")
        print("Install with: pip install rich")
        sys.exit(1)

    tui = BazingaTUI()
    asyncio.run(tui.run())


if __name__ == "__main__":
    run_tui()
